#!/usr/bin/env python3
"""
Merge V3 Analysis Results
Combines multiple JSON result files into one merged file

Requirements:
    - pandas: pip install pandas
"""

import json
import glob
from datetime import datetime
from pathlib import Path

try:
    import pandas as pd
except ImportError:
    print("âŒ Error: pandas is required for this script")
    print("   Install with: pip install pandas")
    exit(1)


def merge_results():
    """Merge all V3 result files"""
    
    print("="*70)
    print("MERGING V3 ANALYSIS RESULTS")
    print("="*70)
    
    # Find all result files (both patterns for flexibility)
    result_files = sorted(set(
        glob.glob('outputs/v3_full_*.json') + 
        glob.glob('outputs/v3_results_*.json')
    ))
    print(f"\nðŸ“‚ Found {len(result_files)} result files:")
    for f in result_files:
        size = Path(f).stat().st_size / (1024*1024)  # MB
        print(f"   - {f} ({size:.1f} MB)")
    
    if not result_files:
        print("\nâŒ No result files found!")
        print("   Looking for: outputs/v3_full_*.json or outputs/v3_results_*.json")
        return
    
    # Merge all results
    all_results = []
    all_errors = []
    
    print(f"\nðŸ“¥ Merging results...")
    for file in result_files:
        try:
            with open(file, 'r') as f:
                data = json.load(f)
                all_results.extend(data.get('results', []))
                all_errors.extend(data.get('errors', []))
        except Exception as e:
            print(f"   âš ï¸  Error reading {file}: {e}")
    
    print(f"   - Total results loaded: {len(all_results)}")
    
    # Remove duplicates (by instance_id)
    seen = set()
    unique_results = []
    duplicates = 0
    missing_ids = 0
    
    for r in all_results:
        iid = r.get('instance_id')
        if not iid:
            # Track results with missing instance_id separately
            missing_ids += 1
            unique_results.append(r)
        elif iid not in seen:
            seen.add(iid)
            unique_results.append(r)
        else:
            duplicates += 1
    
    print(f"   - Unique instances: {len(unique_results)}")
    if duplicates > 0:
        print(f"   - Duplicates removed: {duplicates}")
    if missing_ids > 0:
        print(f"   - Results with missing IDs: {missing_ids}")
    
    # Count successful vs errors
    successful = [r for r in unique_results if not r.get('errors')]
    with_errors = [r for r in unique_results if r.get('errors')]
    
    print(f"\nðŸ“Š Statistics:")
    print(f"   âœ… Successful: {len(successful)}")
    print(f"   âš ï¸  With errors: {len(with_errors)}")
    print(f"   âŒ Failed completely: {len(all_errors)}")
    
    # Save merged JSON
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    merged = {
        'metadata': {
            'timestamp': datetime.now().isoformat(),
            'version': 'v3',
            'total_instances': len(unique_results),
            'successful': len(successful),
            'with_errors': len(with_errors),
            'merged_files': len(result_files),
            'source_files': result_files
        },
        'results': unique_results,
        'errors': all_errors
    }
    
    json_file = f'outputs/v3_merged_{timestamp}.json'
    with open(json_file, 'w') as f:
        json.dump(merged, f, indent=2)
    
    json_size = Path(json_file).stat().st_size / (1024*1024)
    print(f"\nðŸ’¾ Merged JSON saved:")
    print(f"   {json_file} ({json_size:.1f} MB)")
    
    # Create merged CSV
    print(f"\nðŸ“Š Creating merged CSV...")
    
    csv_rows = []
    for result in unique_results:
        row = {
            'instance_id': result.get('instance_id'),
            'repo_name': result.get('repo_name'),
            'analysis_time': result.get('analysis_time', 0),
            'has_errors': bool(result.get('errors'))
        }
        
        # Extract scope info
        scope = result.get('scope', {})
        row['scope_size'] = scope.get('total_size', 0)
        row['primary_files'] = len(scope.get('primary', []))
        row['secondary_files'] = len(scope.get('secondary', []))
        row['direct_imports'] = len(scope.get('direct_imports', []))
        
        # Extract metrics from the actual structure
        metrics = result.get('metrics', {})
        overall = metrics.get('overall_metrics', {})
        summary = overall.get('summary', {})
        
        # DFG-GED
        graph_metrics = summary.get('graph', {})
        dfg_ged = graph_metrics.get('DFG_GED', {})
        row['dfg_ged_sum'] = dfg_ged.get('sum', -1)
        row['dfg_ged_avg'] = dfg_ged.get('avg', -1)
        row['dfg_ged_max'] = dfg_ged.get('max', -1)
        
        # AST-GED
        ast_metrics = summary.get('ast', {})
        ast_ged = ast_metrics.get('AST_GED', {})
        row['ast_ged_sum'] = ast_ged.get('sum', -1)
        row['ast_ged_avg'] = ast_ged.get('avg', -1)
        row['ast_ged_max'] = ast_ged.get('max', -1)
        
        # CFG-GED
        cfg_ged = graph_metrics.get('CFG_GED', {})
        row['cfg_ged_sum'] = cfg_ged.get('sum', -1)
        row['cfg_ged_avg'] = cfg_ged.get('avg', -1)
        row['cfg_ged_max'] = cfg_ged.get('max', -1)
        
        csv_rows.append(row)
    
    df = pd.DataFrame(csv_rows)
    csv_file = f'outputs/v3_merged_summary_{timestamp}.csv'
    df.to_csv(csv_file, index=False)
    
    csv_size = Path(csv_file).stat().st_size / 1024
    print(f"   {csv_file} ({csv_size:.1f} KB)")
    
    # Summary statistics (filter out -1 values for accurate metrics)
    print(f"\nðŸ“ˆ Summary Statistics:")
    print(f"   Total instances: {len(df)}")
    
    # Filter out -1 (missing) values before calculating averages
    dfg_avg_valid = df[df['dfg_ged_avg'] != -1]['dfg_ged_avg']
    dfg_max_valid = df[df['dfg_ged_max'] != -1]['dfg_ged_max']
    
    if len(dfg_avg_valid) > 0:
        print(f"   Average DFG-GED: {dfg_avg_valid.mean():.2f} ({len(dfg_avg_valid)} valid)")
        print(f"   Max DFG-GED: {dfg_max_valid.max():.2f}")
    else:
        print(f"   Average DFG-GED: N/A (no valid metrics)")
        print(f"   Max DFG-GED: N/A")
    
    print(f"   Average scope size: {df['scope_size'].mean():.1f} files")
    print(f"   Average analysis time: {df['analysis_time'].mean():.1f}s")
    
    print(f"\nâœ… Merge complete!")
    print("="*70)


if __name__ == '__main__':
    merge_results()
