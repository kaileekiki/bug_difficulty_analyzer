#!/usr/bin/env python3
"""
Hugging Faceì—ì„œ SWE-bench Verified ë°ì´í„°ì…‹ ë¡œë“œ
"""

import json
from pathlib import Path
from typing import List, Dict, Any

class SWEBenchLoader:
    def __init__(self, cache_dir: str = "datasets"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.cache_file = self.cache_dir / "swebench_verified.json"
    
    def download_dataset(self, force: bool = False) -> Path:
        """Hugging Faceì—ì„œ SWE-bench Verified ë‹¤ìš´ë¡œë“œ"""
        if self.cache_file.exists() and not force:
            print(f"âœ… ë°ì´í„°ì…‹ì´ ì´ë¯¸ ìºì‹œë¨: {self.cache_file}")
            return self.cache_file
        
        print("ğŸ“¥ Hugging Faceì—ì„œ SWE-bench Verified ë‹¤ìš´ë¡œë“œ ì¤‘...")
        print(f"   ì €ì¥ ìœ„ì¹˜: {self.cache_file}")
        
        try:
            from datasets import load_dataset
            
            # Hugging Faceì—ì„œ ë¡œë“œ
            dataset = load_dataset("princeton-nlp/SWE-bench_Verified", split="test")
            
            print(f"âœ… {len(dataset)}ê°œ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            data = [dict(item) for item in dataset]
            
            # ìºì‹œì— ì €ì¥
            print("ğŸ’¾ JSON íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            file_size_mb = self.cache_file.stat().st_size / 1024 / 1024
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {self.cache_file}")
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")
            
            return self.cache_file
            
        except ImportError:
            print("âŒ 'datasets' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            print("   ì„¤ì¹˜ ëª…ë ¹ì–´: pip install datasets")
            raise
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("\nğŸ’¡ ëŒ€ì•ˆ: ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ")
            print("   https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified")
            raise
    
    def load_dataset(self) -> List[Dict[str, Any]]:
        """ìºì‹œëœ ë°ì´í„°ì…‹ ë¡œë“œ"""
        if not self.cache_file.exists():
            raise FileNotFoundError(
                f"ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.cache_file}\n"
                f"ë¨¼ì € download_dataset()ì„ ì‹¤í–‰í•˜ì„¸ìš”"
            )
        
        print(f"ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {self.cache_file}")
        with open(self.cache_file, encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… {len(data)}ê°œ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œë¨")
        return data
    
    def get_cache_path(self) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return self.cache_file
    
    def is_cached(self) -> bool:
        """ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        return self.cache_file.exists()