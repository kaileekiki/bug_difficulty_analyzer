#!/usr/bin/env python3
"""
Hugging Faceì—ì„œ SWE-bench Verified ë°ì´í„°ì…‹ ë¡œë“œ
"""

import json
from pathlib import Path
from typing import List, Dict, Any

class SWEBenchLoader:
    def __init__(self, cache_dir: str = "datasets", dataset_dir: str = None):
        """
        Args:
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: "datasets")
            dataset_dir: ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° (cache_dirì™€ ë™ì¼)
        """
        # dataset_dirì´ ì œê³µë˜ë©´ ìš°ì„  ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
        if dataset_dir is not None:
            cache_dir = dataset_dir
            
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.cache_file = self.cache_dir / "swebench_verified.json"
    
    def download_dataset(self, force: bool = False) -> Path:
        """Hugging Faceì—ì„œ SWE-bench Verified ë‹¤ìš´ë¡œë“œ"""
        if self.cache_file.exists() and not force:
            print(f"âœ… ë°ì´í„°ì…‹ì´ ì´ë¯¸ ìºì‹œë¨: {self.cache_file}")
            return self.cache_file
        
        print("ðŸ“¥ Hugging Faceì—ì„œ SWE-bench Verified ë‹¤ìš´ë¡œë“œ ì¤‘...")
        print(f"   ì €ìž¥ ìœ„ì¹˜: {self.cache_file}")
        
        try:
            from datasets import load_dataset
            
            # Hugging Faceì—ì„œ ë¡œë“œ
            dataset = load_dataset("princeton-nlp/SWE-bench_Verified", split="test")
            
            print(f"âœ… {len(dataset)}ê°œ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            data = [dict(item) for item in dataset]
            
            # ìºì‹œì— ì €ìž¥
            print("ðŸ’¾ JSON íŒŒì¼ë¡œ ì €ìž¥ ì¤‘...")
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            file_size_mb = self.cache_file.stat().st_size / 1024 / 1024
            print(f"âœ… ì €ìž¥ ì™„ë£Œ: {self.cache_file}")
            print(f"ðŸ“Š íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")
            
            return self.cache_file
            
        except ImportError:
            print("âŒ 'datasets' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            print("   ì„¤ì¹˜ ëª…ë ¹ì–´: pip install datasets")
            raise
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("\nðŸ’¡ ëŒ€ì•ˆ: ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ")
            print("   https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified")
            raise
    
    def load_dataset(self) -> List[Dict[str, Any]]:
        """ìºì‹œëœ ë°ì´í„°ì…‹ ë¡œë“œ"""
        if not self.cache_file.exists():
            raise FileNotFoundError(
                f"ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.cache_file}\n"
                f"ë¨¼ì € download_dataset()ì„ ì‹¤í–‰í•˜ì„¸ìš”"
            )
        
        print(f"ðŸ“‚ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {self.cache_file}")
        with open(self.cache_file, encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… {len(data)}ê°œ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œë¨")
        return data
    
    def get_cache_path(self) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return self.cache_file
    
    def is_cached(self) -> bool:
        """ìºì‹œ íŒŒì¼ì´ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸"""
        return self.cache_file.exists()
    
    def create_mock_dataset(self, n: int = 10) -> List[Dict[str, Any]]:
        """
        Create mock dataset for testing.
        
        Args:
            n: Number of mock instances
            
        Returns:
            List of mock instances
        """
        mock_instances = []
        
        for i in range(n):
            mock_instances.append({
                'instance_id': f'mock-{i+1:03d}',
                'repo': 'https://github.com/octocat/Hello-World',
                'base_commit': 'master',
                'patch': f"""
diff --git a/test_{i}.py b/test_{i}.py
index 1234567..abcdefg 100644
--- a/test_{i}.py
+++ b/test_{i}.py
@@ -1,3 +1,4 @@
+# Modified line {i}
 def test_{i}():
     pass
""",
                'problem_statement': f'Mock problem statement {i}'
            })
        
        return mock_instances